// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview A flow to translate audio and respond in the selected language.
 *
 * - translateAudio - A function that handles the audio translation and response generation process.
 * - TranslateAudioInput - The input type for the translateAudio function.
 * - TranslateAudioOutput - The return type for the translateAudio function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';
import { detectEmotion } from '../tools/detect-emotion';
import { translateText } from '../tools/translate-text';

const TranslateAudioInputSchema = z.object({
  audioDataUri: z
    .string()
    .describe(
      "A recorded audio, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'."
    ),
  language: z.string().describe('The target language for translation.'),
});
export type TranslateAudioInput = z.infer<typeof TranslateAudioInputSchema>;

const TranslateAudioOutputSchema = z.object({
  translatedText: z.string().describe('The translated text of the audio.'),
  aiResponse: z.string().describe('The AI-generated response in the selected language.'),
});
export type TranslateAudioOutput = z.infer<typeof TranslateAudioOutputSchema>;

export async function translateAudio(input: TranslateAudioInput): Promise<TranslateAudioOutput> {
  return translateAudioFlow(input);
}

const translateAudioFlow = ai.defineFlow(
  {
    name: 'translateAudioFlow',
    inputSchema: TranslateAudioInputSchema,
    outputSchema: TranslateAudioOutputSchema,
  },
  async input => {
    const { audioDataUri, language } = input;

    // Transcribe audio using a tool
    const { text: transcribedText } = await ai.generate({
      model: 'googleai/gemini-2.0-flash',
      prompt: `Transcribe the following audio: {{media url=audioDataUri}}`,
    });

    if (!transcribedText) {
      throw new Error('Could not transcribe audio.');
    }

    // Translate the transcribed text
    const translatedTextResult = await translateText({
      text: transcribedText,
      targetLanguage: language,
    });

    // Detect emotion from the translated text
    const emotion = await detectEmotion({
      text: translatedTextResult.translatedText,
    });

    // Generate supportive responses based on detected emotions using generative AI
    const { text: aiResponse } = await ai.generate({
      model: 'googleai/gemini-2.0-flash',
      prompt: `Generate a supportive response in ${language} based on the following emotion: ${emotion.sentimentAnalysisResult}.\n\nTranslated Text: ${translatedTextResult.translatedText}`,
    });

    if (!aiResponse) {
      throw new Error('Could not generate AI response.');
    }

    return {
      translatedText: translatedTextResult.translatedText,
      aiResponse: aiResponse,
    };
  }
);
